{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import naive_bayes as nb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "# class NaiveBayesClassifier:\n",
    "#     def __init__(self, alpha = 1):\n",
    "#         self.dic_data_index = dict()\n",
    "#         self.dic_data_by_class = dict()\n",
    "#         self.dic_data_posterior = dict()\n",
    "#         self.dic_data_prob_fitur = dict()\n",
    "#         self.prior = dict()\n",
    "#         self.class_ = 0\n",
    "#         self.alpha = alpha\n",
    "#         self.list_post = list()\n",
    "# #         self.count_doc_c = dict()\n",
    "\n",
    "#     def train (self, X, y):\n",
    "# #         print(X)\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "        \n",
    "#         vectorizer = CountVectorizer(binary=True)\n",
    "#         self.X = vectorizer.fit_transform(X).A\n",
    "#         self.fitur = vectorizer.get_feature_names()\n",
    "#         self.len_fitur = len(self.fitur)\n",
    "#         self.y = np.array(self.y)\n",
    "#         self.class_ = sorted(set(y))\n",
    "        \n",
    "#         self.prior_class = dict(zip(Counter(self.y).keys(), Counter(self.y).values()))\n",
    "#         self.count_doc_c = self.prior_class.copy()\n",
    "#         for key, value in self.prior_class.items():\n",
    "# #             self.count_doc_c.update({key:len(self.y)})\n",
    "#             self.prior_class.update({key:value/len(self.y)})\n",
    "        \n",
    "#         #menghitung jumlah class\n",
    "#         self.len_data = len(self.y)\n",
    "\n",
    "#         #mencari index data untuk class tertentu\n",
    "# #         self.dic_data_index = dict()\n",
    "#         for i in self.class_:\n",
    "#             isi_list = list()\n",
    "#             for index, j in enumerate(self.y):\n",
    "#         #         print(j)\n",
    "#                 if i == j:\n",
    "#                     isi_list.append(index)\n",
    "#             self.dic_data_index.update({i:isi_list})\n",
    "            \n",
    "# #         self.dic_data_by_class = dict()\n",
    "#         for key, value in self.dic_data_index.items():\n",
    "#             self.dic_data_by_class.update({key:(self.X[value])})\n",
    "#         # del self.dic_data_index\n",
    "        \n",
    "#         self.count_fitur_c = dict()\n",
    "#         self.dic_data_prob_fitur = dict()\n",
    "#         for c, value in self.dic_data_by_class.items():\n",
    "#             count_per_doc = list()\n",
    "#             prob_fitur = list()\n",
    "#             sum_value  = value.sum()\n",
    "#             for ix, f in enumerate(value.transpose()):\n",
    "# #                 prob_fitur.append((f.sum()+self.alpha)/(len(value)+self.len_fitur))\n",
    "#                 count_per_doc.append(f.sum())\n",
    "#                 prob_fitur.append((f.sum()/(len(value)+self.len_fitur)))\n",
    "# #                 print(c,str(f.sum()), \"+\",str(self.alpha),\"/\", str(len(value)),\"+\", str(self.len_fitur), self.fitur[ix])\n",
    "            \n",
    "#             _dict_count_fitur = dict(zip(self.fitur, count_per_doc))\n",
    "#             bobot_fitur = dict(zip(self.fitur,prob_fitur))\n",
    "            \n",
    "#             self.count_fitur_c.update({c:_dict_count_fitur})\n",
    "#             self.dic_data_prob_fitur.update({c:bobot_fitur})\n",
    "            \n",
    "    \n",
    "#     def predict(self, X):\n",
    "# #         tostr = lamda str(x):x\n",
    "#         if self.alpha <= 0:\n",
    "#             raise Exception(\"alpha tidak boleh kurang dari atau sama dengan 0, alpha=\"+str(self.alpha)) \n",
    "#         X = sorted(set(X.split()))\n",
    "#         try:\n",
    "#             self.dict_predict = dict()\n",
    "#             for c, value in self.dic_data_prob_fitur.items():\n",
    "#     #             print(len(value))\n",
    "\n",
    "#                 bobot_fitur = list()\n",
    "#                 for kata in X:\n",
    "#     #                 print(kata)\n",
    "#                     if kata in value:\n",
    "#     #                     print(value[kata])\n",
    "#                         # print(c,kata,value[kata])\n",
    "#                         bobot_fitur.append((self.count_fitur_c[c][kata]+self.alpha)/(self.count_doc_c[c]+self.len_fitur))\n",
    "#                         self.list_post.append(\"P({}|{})=({}+{})/({}+{} = {})\"\n",
    "#                         .format(kata,c,self.count_fitur_c[c][kata],self.alpha,self.count_doc_c[c],self.len_fitur, (self.count_fitur_c[c][kata]+self.alpha)/(self.count_doc_c[c]+self.len_fitur)))\n",
    "#     #                     print((self.count_fitur_c[c][kata]+self.alpha)/(self.count_doc_c[c]+self.len_fitur))\n",
    "#     #  \n",
    "#     #                     print(\"P\"+\"(\"+kata+\"|\"+c+\")=\"+str((value[kata]+(self.alpha/(self.count_doc_c[c]+self.len_fitur)))))\n",
    "#     #                     \n",
    "#                 if len(bobot_fitur)>0:\n",
    "#                     post_prior = np.prod(bobot_fitur)*self.prior_class[c]\n",
    "#     #                 print(type(bobot_fitur))\n",
    "#                     bobot_fitur_ = [str(round(x, 3)) for x in bobot_fitur]\n",
    "#                     self.list_post.append(\"P({}|{}) = {} x {} = {}\".format(c,\"X\",self.prior_class[c], \" x \".join(bobot_fitur_), post_prior,20))\n",
    "#                     self.list_post.append(\"===================================\")\n",
    "#     #                 print(bobot_fitur)\n",
    "#                     self.dict_predict.update({c:post_prior})\n",
    "#     #             print(\"\")\n",
    "#             return max(self.dict_predict.items(), key=operator.itemgetter(1))[0]\n",
    "#         except:\n",
    "#             print(\"err404or\")\n",
    "#             return max(self.prior_class.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_separate(y, complement=False):\n",
    "    kelas = sorted(set(y))\n",
    "    \n",
    "    dict_index = dict()\n",
    "    for c in kelas:\n",
    "        index = list()\n",
    "        for ix, c_ in enumerate(y):\n",
    "            if complement==False and c==c_:\n",
    "                index.append(ix)\n",
    "            elif complement==True and c!=c_:\n",
    "                index.append(ix)\n",
    "        dict_index.update({c:index})\n",
    "    return dict_index\n",
    "\n",
    "def prior_(y):\n",
    "    unik = sorted(set(y))\n",
    "    dict_p = dict()\n",
    "    for c in unik:\n",
    "        count = y.tolist().count(c)\n",
    "        dict_p.update({c:count/len(y)})\n",
    "    return dict_p \n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        self.dict_nb = 0\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        vectorizer = CountVectorizer(binary=True)\n",
    "        self.model_w = vectorizer.fit(X)\n",
    "        self.X = self.model_w.transform(X)\n",
    "        \n",
    "        self.class_ = sorted(set(y))\n",
    "        self.prior = prior_(y)\n",
    "        index_data = data_separate(y)\n",
    "        self.an = len(self.X.A[0])\n",
    "#         self.X = X\n",
    "        \n",
    "        self.dict_nb = dict()\n",
    "        for c in self.class_:\n",
    "            n_yi = np.sum(self.X[index_data[c]].A, axis=0)\n",
    "            n_y = len(self.X[index_data[c]].A)\n",
    "            self.dict_nb.update({c:{}})\n",
    "            self.dict_nb[c][\"n_y\"] = n_y\n",
    "            self.dict_nb[c][\"n_yi\"] = n_yi\n",
    "            \n",
    "    def predict(self, X):\n",
    "        self.X = self.model_w.transform(X)\n",
    "        result = list()\n",
    "        for i in self.X.A:\n",
    "            index = list()\n",
    "            for ix, f in enumerate(i):\n",
    "                if f>0:\n",
    "                    index.append(ix)\n",
    "            \n",
    "            list_pst = list()\n",
    "            for c in self.class_:\n",
    "                weight = (self.dict_nb[c][\"n_yi\"][index]+self.alpha)/(self.dict_nb[c][\"n_y\"]+self.an)\n",
    "                posterior = np.prod(weight)*self.prior[c]\n",
    "                list_pst.append(posterior)\n",
    "            result.append(self.class_[list_pst.index(max(list_pst))])\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = pd.read_excel(\"Book1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array(foo.label.tolist())\n",
    "komentar = np.array(foo.komentar.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['obat herbal sehat murah',\n",
       "       'ingin putih glowing langsing ideal konsultasi langsung',\n",
       "       'mau punya kulit putih harga murah add putih kulit',\n",
       "       'mantap terima kasih pak',\n",
       "       'Tetap satu pintu Pak nanti Dana Siluman',\n",
       "       'Ini mantul mantap betul', 'sehat terus pak'], dtype='<U54')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komentar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nb.NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'komentar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9196f9e3df6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkomentar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'komentar' is not defined"
     ]
    }
   ],
   "source": [
    "model.alpha = 1\n",
    "model.train(komentar, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spam']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([\"obat herbal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'non spam': {'n_y': 4,\n",
       "  'n_yi': array([0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 3, 1,\n",
       "         0, 0, 1, 1, 1, 1, 1, 1])},\n",
       " 'spam': {'n_y': 3,\n",
       "  'n_yi': array([1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0,\n",
       "         1, 2, 0, 1, 0, 0, 0, 0])}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dict_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029411764705882353"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.dict_nb['non spam']['n_yi'][0]+1) / (model.dict_nb['non spam']['n_y']+30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06060606060606061"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.dict_nb['spam']['n_yi'][0]+1) / (model.dict_nb['spam']['n_y']+30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"obat herbal langsing sehat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P(herbal|non spam)=(0+1)/(4+30 = 0.029411764705882353)',\n",
       " 'P(langsing|non spam)=(0+1)/(4+30 = 0.029411764705882353)',\n",
       " 'P(obat|non spam)=(0+1)/(4+30 = 0.029411764705882353)',\n",
       " 'P(sehat|non spam)=(1+1)/(4+30 = 0.058823529411764705)',\n",
       " 'P(non spam|X) = 0.5714285714285714 x 0.029 x 0.029 x 0.029 x 0.059 = 8.552169086645446e-07',\n",
       " '===================================',\n",
       " 'P(herbal|spam)=(1+1)/(3+30 = 0.06060606060606061)',\n",
       " 'P(langsing|spam)=(1+1)/(3+30 = 0.06060606060606061)',\n",
       " 'P(obat|spam)=(1+1)/(3+30 = 0.06060606060606061)',\n",
       " 'P(sehat|spam)=(1+1)/(3+30 = 0.06060606060606061)',\n",
       " 'P(spam|X) = 0.42857142857142855 x 0.061 x 0.061 x 0.061 x 0.061 = 5.782124489863032e-06',\n",
       " '===================================']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.list_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029411764705882353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0+1)/(4+30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "a.append(\"{} {} + {}\".format(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 + 3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2,2,2])\n",
    "b = np.array([3,3,3])\n",
    "\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
