{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naive_bayes as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "(5, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as tf\n",
    "# from sklearn.feature_extraction.text import CountVectorizer as tf\n",
    "corpus = [\n",
    "    'Chinese Chinese Shanghai',\n",
    "    'Chinese Beijing Chinese',\n",
    "    'Chinese Macao',\n",
    "    'Tokyo Japan Chinese',\n",
    "    'Tokyo Japan',\n",
    "]\n",
    "vectorizer = tf()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "modelT = vectorizer.fit(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print(X.shape)\n",
    "fitur  = vectorizer.get_feature_names()\n",
    "fitur\n",
    "\n",
    "# vectorizer = tf(vocabulary = fitur)\n",
    "# # X = vectorizer.fit_transform(corpus)\n",
    "# modelT = vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2,3,4,5],\n",
    "         [1,2,3,4,5]])\n",
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array([\"yes\",\"yes\",\"yes\",'no','no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 0.0 + 1 / 3.1250082352400623 6 beijing\n",
      "no 0.44274008962926825 + 1 / 3.1250082352400623 6 chinese\n",
      "no 1.341134072805397 + 1 / 3.1250082352400623 6 japan\n",
      "no 0.0 + 1 / 3.1250082352400623 6 macao\n",
      "no 0.0 + 1 / 3.1250082352400623 6 shanghai\n",
      "no 1.341134072805397 + 1 / 3.1250082352400623 6 tokyo\n",
      "yes 0.6637818525837387 + 1 / 4.185508192682794 6 beijing\n",
      "yes 1.9866977074221843 + 1 / 4.185508192682794 6 chinese\n",
      "yes 0.0 + 1 / 4.185508192682794 6 japan\n",
      "yes 0.8712467800931323 + 1 / 4.185508192682794 6 macao\n",
      "yes 0.6637818525837387 + 1 / 4.185508192682794 6 shanghai\n",
      "yes 0.0 + 1 / 4.185508192682794 6 tokyo\n"
     ]
    }
   ],
   "source": [
    "model = nb.MultinominalNaiveBayes(alpha = 1)\n",
    "model.train(X,y, fitur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = modelT.transform([\"Tokyo Tokyo Tokyo Tokyo Tokyo\"])\n",
    "model.predict(new_data[0].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.10262496262804988, 'yes': 0.058907222757037914}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': [0.10958894219274003,\n",
       "  0.15810836028153044,\n",
       "  0.2565624065701247,\n",
       "  0.10958894219274003,\n",
       "  0.10958894219274003,\n",
       "  0.2565624065701247],\n",
       " 'yes': [0.16334794701544586,\n",
       "  0.29323011193175513,\n",
       "  0.0981787045950632,\n",
       "  0.18371658484722683,\n",
       "  0.16334794701544586,\n",
       "  0.0981787045950632]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nb.ComplementNaiveBayes()\n",
    "# model.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(new_data[0].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.dic_data_by_class['yes'].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for yes, no in enumerate(model.dic_data_by_class[\"yes\"].A, model.dic_data_by_class[\"no\"].A):\n",
    "#     print(yes, no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class NBC:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dic_data_index = dict()\n",
    "        self.dic_data_by_class = dict()\n",
    "        self.dic_data_posterior = dict()\n",
    "        self.dic_data_prob_fitur = dict()\n",
    "        self.prior = dict()\n",
    "        self.class_ = 0\n",
    "    def train (self, X, y):\n",
    "#         print(X)\n",
    "        X = [np.array(i.split()) for i in X]\n",
    "\n",
    "        X = np.array(X)\n",
    "#         print(X)\n",
    "        y = np.array(y)\n",
    "        self.class_ = sorted(set(y))\n",
    "\n",
    "        for i in self.class_:\n",
    "            isi_list = list()\n",
    "            for index, j in enumerate(y):\n",
    "        #         print(j)\n",
    "                if i == j:\n",
    "                    isi_list.append(index)\n",
    "            self.dic_data_index.update({i:isi_list})\n",
    "\n",
    "        for key, value in self.dic_data_index.items():\n",
    "#             print(X[value])\n",
    "            self.dic_data_by_class.update({key:X[value]})\n",
    "            self.prior.update({key:len(value)/len(y)})\n",
    "\n",
    "        for key, value in self.dic_data_by_class.items():\n",
    "            words = list()\n",
    "#             print(value)\n",
    "            for i in value:\n",
    "                for kata in set(i): #biner\n",
    "                    words.append(kata)\n",
    "            dict_fitur = dict()\n",
    "#             fitur_bobot = list()\n",
    "#             print(words)\n",
    "            for i in words:\n",
    "                prob_fitur_ = words.count(i)/len(value)\n",
    "#                 print(value)\n",
    "#                 print(i,\"|\",words.count(i),\"/\",len(value),\"===\", key)\n",
    "                dict_fitur.update({i:prob_fitur_})\n",
    "#                 fitur_bobot.append(prob_fitur_)\n",
    "    #         print(np.prod(fitur_bobot))\n",
    "            self.dic_data_prob_fitur.update({key:dict_fitur})\n",
    "#             self.dic_data_posterior.update({key:np.prod(fitur_bobot)})\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.split()\n",
    "        self.dict_predict = dict()\n",
    "        for c, value in self.dic_data_prob_fitur.items():\n",
    "            \n",
    "            bobot_fitur = list()\n",
    "            for kata in X:\n",
    "#                 print(kata)\n",
    "                if kata in value:\n",
    "                    print(c,kata,value[kata])\n",
    "                    bobot_fitur.append(value[kata])\n",
    "#                     print(c, value[kata])\n",
    "            if len(bobot_fitur)>0:\n",
    "                post_prior = np.prod(bobot_fitur)*self.prior[c]\n",
    "#                 print(post_prior)\n",
    "                self.dict_predict.update({c:post_prior})\n",
    "        return max(self.dict_predict.items(), key=operator.itemgetter(1))[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  _counter (corpus, y)\n",
    "model  = NBC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(corpus, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no': 0.4, 'yes': 0.6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'no': {'Japan': 1.0, 'Chinese': 0.5, 'Tokyo': 1.0},\n",
       " 'yes': {'Shanghai': 0.3333333333333333,\n",
       "  'Chinese': 1.0,\n",
       "  'Beijing': 0.3333333333333333,\n",
       "  'Macao': 0.3333333333333333}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.prior)\n",
    "model.dic_data_prob_fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no Tokyo 1.0\n",
      "no Chinese 0.5\n",
      "no Japan 1.0\n",
      "yes Chinese 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Tokyo Chinese Japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.25}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dict_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.dic_data_by_class['no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': array([array(['Tokyo', 'Japan', 'Chinese'], dtype='<U7')], dtype=object),\n",
       " 'yes': array([array(['Chinese', 'Chinese', 'Shanghai'], dtype='<U8'),\n",
       "        array(['Chinese', 'Beijing', 'Chinese'], dtype='<U7'),\n",
       "        array(['Chinese', 'Macao'], dtype='<U7')], dtype=object)}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dic_data_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': {'Chinese': 1.0, 'Tokyo': 1.0, 'Japan': 1.0},\n",
       " 'yes': {'Chinese': 1.0,\n",
       "  'Shanghai': 0.3333333333333333,\n",
       "  'Beijing': 0.3333333333333333,\n",
       "  'Macao': 0.3333333333333333}}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dic_data_prob_fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "class ComplementNaiveBayes:\n",
    "    def __init__(self,alpha = 1):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def train(self, X, y, fitur):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.fitur = fitur\n",
    "        self.len_fitur = len(X.A[0])\n",
    "#         self.fitur = fitur\n",
    "        \n",
    "        self.class_ = sorted(set(self.y))\n",
    "        self.len_fitur = len(self.y)\n",
    "\n",
    "        #mencari index data dengan class tertentu\n",
    "        self.dic_data_index = dict()\n",
    "        for i in self.class_:\n",
    "            isi_list = list()\n",
    "            for index, j in enumerate(self.y):\n",
    "                if i != j: #salah satu dari tahap complement\n",
    "                    isi_list.append(index)\n",
    "            self.dic_data_index.update({i:isi_list})\n",
    "            \n",
    "        self.dic_data_by_class = dict()\n",
    "        for key, value in self.dic_data_index.items():\n",
    "            self.dic_data_by_class.update({key:(self.X[value])})\n",
    "\n",
    "        self.complement = dict()\n",
    "        for c, value in self.dic_data_by_class.items():\n",
    "            prob_wci = list()\n",
    "            sum_value  = value.sum()\n",
    "#             print(sum_value)\n",
    "#           Hitung Complement\n",
    "            for ix, f in enumerate(value.transpose()):\n",
    "#                 f = f.sum() + (self.alpha*len(self.dic_data_index[c])) / sum_value+(self.alpha*len(self.dic_data_index[c]))\n",
    "#                 f = (f.sum()+self.alpha)/(sum_value+self.len_fitur)\n",
    "                f2 = (f.sum()+self.alpha)/(sum_value+self.len_fitur)\n",
    "#                 print(self.fitur[ix], \"|\",c,str(f.sum()), \"+\",str(self.alpha),\"/\", str(sum_value), \"+\",str(self.len_fitur), \"=\", str(f2))\n",
    "                f = (f.sum()+self.alpha)/(sum_value+self.len_fitur)\n",
    "                \n",
    "#                 print(f, end=\" \")\n",
    "                wci = np.log(f)\n",
    "#                 print(wci)\n",
    "                prob_wci.append(wci)\n",
    "#             print(np.sqrt(sum(prob_wci)))\n",
    "#             print(\"\")\n",
    "            norm_wci = np.array(prob_wci)/sum(prob_wci)\n",
    "            self.complement.update({c:norm_wci})\n",
    "\n",
    "    def predict(self, X_predict):\n",
    "        self.X_predict = X_predict\n",
    "        self.inf_dict = dict()\n",
    "        for c in self.class_:\n",
    "            self.inf_dict.update({c:np.prod(np.power(self.complement[c],self.X_predict))})\n",
    "#             print(c,self.complement[c], self.X_predict, \"= \", np.prod(np.power(self.complement[c],self.X_predict)))\n",
    "        return min(self.inf_dict.items(), key=operator.itemgetter(1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ComplementNaiveBayes(alpha = 10)\n",
    "model2.train(X, y, fitur)\n",
    "new_data = modelT.transform([\"Tokyo Japan\"])\n",
    "# print(fitur)\n",
    "model2.predict(new_data[0].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.05325811855968479, 'yes': 0.08645459185201433}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.inf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06617165\n",
      "0.6741498\n"
     ]
    }
   ],
   "source": [
    "print(0.21323433*5)\n",
    "print(0.13482996*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(0.5+0.08333333333333333+0.08333333333333333)\n",
    "print(0.2857142857142857 + 0.2857142857142857+ 0.2857142857142857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.dic_data_by_class['yes'].A)\n",
    "# print(\"\")\n",
    "# print(model.dic_data_by_class['no'].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': array([0.15987671, 0.10495551, 0.21323433, 0.14882239, 0.15987671,\n",
       "        0.21323433]),\n",
       " 'yes': array([0.19075249, 0.15808262, 0.13482996, 0.19075249, 0.19075249,\n",
       "        0.13482996])}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5.])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([10,10,10])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
