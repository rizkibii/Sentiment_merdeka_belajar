{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NaiveBayesC:\n",
    "#     def __init__(self,alpha = 1):\n",
    "#         self.alpha = alpha\n",
    "        \n",
    "#     def train(self, X, y, fitur):\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.fitur = fitur\n",
    "#         # print(X)\n",
    "#         self.len_fitur = len(X.A[0])\n",
    "# #         self.fitur = fitur\n",
    "        \n",
    "#         self.class_ = sorted(set(self.y))\n",
    "\n",
    "#         self.prior_class = dict(zip(Counter(self.y).keys(), Counter(self.y).values()))\n",
    "#         for key, value in self.prior_class.items():\n",
    "#             self.prior_class.update({key:value/len(self.y)})\n",
    "        \n",
    "#         #menghitung jumlah class\n",
    "#         self.len_data = len(self.y)\n",
    "\n",
    "#         #mencari index data untuk class tertentu\n",
    "#         self.dic_data_index = dict()\n",
    "#         for i in self.class_:\n",
    "#             isi_list = list()\n",
    "#             for index, j in enumerate(self.y):\n",
    "#         #         print(j)\n",
    "#                 if i == j:\n",
    "#                     isi_list.append(index)\n",
    "#             self.dic_data_index.update({i:isi_list})\n",
    "            \n",
    "#         self.dic_data_by_class = dict()\n",
    "#         for key, value in self.dic_data_index.items():\n",
    "#             self.dic_data_by_class.update({key:(self.X[value])})\n",
    "# #         dic_data_index\n",
    "\n",
    "#         self.posterior = dict()\n",
    "#         for c, value in self.dic_data_by_class.items():\n",
    "#             prob_fitur = list()\n",
    "#             sum_value  = value.sum()\n",
    "#             for ix, f in enumerate(value.transpose()):\n",
    "#                 prob_fitur.append((f.sum()+self.alpha)/(sum_value+self.len_fitur))\n",
    "#                 print(c,str(f.sum()), \"+\",str(self.alpha),\"/\", str(sum_value), str(self.len_fitur), self.fitur[ix])\n",
    "#             self.posterior.update({c:prob_fitur})\n",
    "# #         print(self.posterior)\n",
    "\n",
    "#     def predict(self, X_predict):\n",
    "#         self.X_predict = X_predict\n",
    "#         self.inf_dict = dict()\n",
    "#         for c in self.class_: \n",
    "# #             self.sum_predict = dict()\n",
    "#             self.inf_dict.update({c:np.prod(np.power(self.posterior[c],self.X_predict))*self.prior_class[c]})\n",
    "#         return max(self.inf_dict.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha = 1):\n",
    "        self.dic_data_index = dict()\n",
    "        self.dic_data_by_class = dict()\n",
    "        self.dic_data_posterior = dict()\n",
    "        self.dic_data_prob_fitur = dict()\n",
    "        self.prior = dict()\n",
    "        self.class_ = 0\n",
    "        self.alpha = alpha\n",
    "#         self.count_doc_c = dict()\n",
    "\n",
    "    def train (self, X, y):\n",
    "#         print(X)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        vectorizer = CountVectorizer(binary=True)\n",
    "        self.X = vectorizer.fit_transform(X).A\n",
    "        self.fitur = vectorizer.get_feature_names()\n",
    "        self.len_fitur = len(self.fitur)\n",
    "        self.y = np.array(self.y)\n",
    "        self.class_ = sorted(set(y))\n",
    "        \n",
    "        self.prior_class = dict(zip(Counter(self.y).keys(), Counter(self.y).values()))\n",
    "        self.count_doc_c = self.prior_class.copy()\n",
    "        for key, value in self.prior_class.items():\n",
    "#             self.count_doc_c.update({key:len(self.y)})\n",
    "            self.prior_class.update({key:value/len(self.y)})\n",
    "        \n",
    "        #menghitung jumlah class\n",
    "        self.len_data = len(self.y)\n",
    "\n",
    "        #mencari index data untuk class tertentu\n",
    "#         self.dic_data_index = dict()\n",
    "        for i in self.class_:\n",
    "            isi_list = list()\n",
    "            for index, j in enumerate(self.y):\n",
    "        #         print(j)\n",
    "                if i == j:\n",
    "                    isi_list.append(index)\n",
    "            self.dic_data_index.update({i:isi_list})\n",
    "            \n",
    "#         self.dic_data_by_class = dict()\n",
    "        for key, value in self.dic_data_index.items():\n",
    "            self.dic_data_by_class.update({key:(self.X[value])})\n",
    "        del self.dic_data_index\n",
    "        \n",
    "        self.count_fitur_c = dict()\n",
    "        self.dic_data_prob_fitur = dict()\n",
    "        for c, value in self.dic_data_by_class.items():\n",
    "            count_per_doc = list()\n",
    "            prob_fitur = list()\n",
    "            sum_value  = value.sum()\n",
    "            for ix, f in enumerate(value.transpose()):\n",
    "#                 prob_fitur.append((f.sum()+self.alpha)/(len(value)+self.len_fitur))\n",
    "                count_per_doc.append(f.sum())\n",
    "                prob_fitur.append((f.sum()/(len(value)+self.len_fitur)))\n",
    "#                 print(c,str(f.sum()), \"+\",str(self.alpha),\"/\", str(len(value)),\"+\", str(self.len_fitur), self.fitur[ix])\n",
    "            \n",
    "            _dict_count_fitur = dict(zip(self.fitur, count_per_doc))\n",
    "            bobot_fitur = dict(zip(self.fitur,prob_fitur))\n",
    "            \n",
    "            self.count_fitur_c.update({c:_dict_count_fitur})\n",
    "            self.dic_data_prob_fitur.update({c:bobot_fitur})\n",
    "    \n",
    "    def predict(self, X):\n",
    "#         tostr = lamda str(x):x\n",
    "        if self.alpha <= 0:\n",
    "            raise Exception(\"alpha tidak boleh kurang dari atau sama dengan 0, alpha=\"+str(self.alpha)) \n",
    "        X = sorted(set(X.split()))\n",
    "#         try:\n",
    "        self.dict_predict = dict()\n",
    "        for c, value in self.dic_data_prob_fitur.items():\n",
    "#             print(len(value))\n",
    "\n",
    "            bobot_fitur = list()\n",
    "            for kata in X:\n",
    "#                 print(kata)\n",
    "                if kata in value:\n",
    "#                     print(value[kata])\n",
    "                    # print(c,kata,value[kata])\n",
    "                    bobot_fitur.append((value[kata]+self.alpha)/(self.count_doc_c[c]+self.len_fitur))\n",
    "                    print(\"P({}|{})=({}+{})/({}+{})\"\n",
    "                    .format(kata,c,self.count_fitur_c[c][kata],self.alpha,self.count_doc_c[c],self.len_fitur), end=\" = \")\n",
    "                    print((value[kata]+self.alpha)/(self.count_doc_c[c]+self.len_fitur))\n",
    "#  \n",
    "#                     print(\"P\"+\"(\"+kata+\"|\"+c+\")=\"+str((value[kata]+(self.alpha/(self.count_doc_c[c]+self.len_fitur)))))\n",
    "#                     \n",
    "            if len(bobot_fitur)>0:\n",
    "                post_prior = np.prod(bobot_fitur)*self.prior_class[c]\n",
    "#                 print(type(bobot_fitur))\n",
    "                bobot_fitur_ = [str(round(x, 3)) for x in bobot_fitur]\n",
    "                print(\"P({}|{}) = {} x {} = {}\".format(c,\"X\",self.prior_class[c], \" x \".join(bobot_fitur_), post_prior,20))\n",
    "#                 print(bobot_fitur)\n",
    "                self.dict_predict.update({c:post_prior})\n",
    "            print(\"\")\n",
    "        return max(self.dict_predict.items(), key=operator.itemgetter(1))[0]\n",
    "#         except:\n",
    "#             print(\"err404or\")\n",
    "#             return max(self.prior_class.items(), key=operator.itemgetter(1))[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+2\n"
     ]
    }
   ],
   "source": [
    "print(\"{}+{}\".format(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corpus = [\n",
    "    'Chinese Chinese Shanghai',\n",
    "    'Chinese Beijing Chinese',\n",
    "    'Chinese Macao',\n",
    "    'Tokyo Japan Chinese',\n",
    "#     'Tokyo Japan',\n",
    "]\n",
    "\n",
    "y = np.array([\"yes\",\"yes\",\"yes\",'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "courpus = np.array(corpus)\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(corpus, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(beijing|no)=(0+1)/(1+6) = 0.14285714285714285\n",
      "P(japan|no)=(1+1)/(1+6) = 0.16326530612244897\n",
      "P(macao|no)=(0+1)/(1+6) = 0.14285714285714285\n",
      "P(tokyo|no)=(1+1)/(1+6) = 0.16326530612244897\n",
      "P(no|X) = 0.25 x 0.143 x 0.163 x 0.143 x 0.163 = 0.00013599775603702534\n",
      "\n",
      "P(beijing|yes)=(1+1)/(3+6) = 0.1234567901234568\n",
      "P(japan|yes)=(0+1)/(3+6) = 0.1111111111111111\n",
      "P(macao|yes)=(1+1)/(3+6) = 0.1234567901234568\n",
      "P(tokyo|yes)=(0+1)/(3+6) = 0.1111111111111111\n",
      "P(yes|X) = 0.75 x 0.123 x 0.111 x 0.123 x 0.111 = 0.00014112573173691905\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.alpha = 1\n",
    "# print(model.alpha)\n",
    "model.predict(\"japan tokyo Beijing macao\".lower())\n",
    "# model.prior_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': {'beijing': 0,\n",
       "  'chinese': 1,\n",
       "  'japan': 1,\n",
       "  'macao': 0,\n",
       "  'shanghai': 0,\n",
       "  'tokyo': 1},\n",
       " 'yes': {'beijing': 1,\n",
       "  'chinese': 3,\n",
       "  'japan': 0,\n",
       "  'macao': 1,\n",
       "  'shanghai': 1,\n",
       "  'tokyo': 0}}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_fitur_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.bobot_fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.00013599775603702534, 'yes': 0.0001881676423158921}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dict_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17142857142857143"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no\n",
    "0.42857142857142855*model.prior_class['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#yes\n",
    "0.2222222222222222*model.prior_class['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 0.6, 'no': 0.4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prior_class#model.prior_class['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prior_class['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2+2)/(4+6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333333"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2/4)+(2/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 11\n",
    "fitur = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021998240140788737"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0+x)/(4+fitur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021998240140788737"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/(4+fitur)+(x/(4+fitur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2+1)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2/4)+(1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0/4)+(1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
