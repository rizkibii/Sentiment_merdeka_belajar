{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NaiveBayesC:\n",
    "#     def __init__(self,alpha = 1):\n",
    "#         self.alpha = alpha\n",
    "        \n",
    "#     def train(self, X, y, fitur):\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.fitur = fitur\n",
    "#         # print(X)\n",
    "#         self.len_fitur = len(X.A[0])\n",
    "# #         self.fitur = fitur\n",
    "        \n",
    "#         self.class_ = sorted(set(self.y))\n",
    "\n",
    "#         self.prior_class = dict(zip(Counter(self.y).keys(), Counter(self.y).values()))\n",
    "#         for key, value in self.prior_class.items():\n",
    "#             self.prior_class.update({key:value/len(self.y)})\n",
    "        \n",
    "#         #menghitung jumlah class\n",
    "#         self.len_data = len(self.y)\n",
    "\n",
    "#         #mencari index data untuk class tertentu\n",
    "#         self.dic_data_index = dict()\n",
    "#         for i in self.class_:\n",
    "#             isi_list = list()\n",
    "#             for index, j in enumerate(self.y):\n",
    "#         #         print(j)\n",
    "#                 if i == j:\n",
    "#                     isi_list.append(index)\n",
    "#             self.dic_data_index.update({i:isi_list})\n",
    "            \n",
    "#         self.dic_data_by_class = dict()\n",
    "#         for key, value in self.dic_data_index.items():\n",
    "#             self.dic_data_by_class.update({key:(self.X[value])})\n",
    "# #         dic_data_index\n",
    "\n",
    "#         self.posterior = dict()\n",
    "#         for c, value in self.dic_data_by_class.items():\n",
    "#             prob_fitur = list()\n",
    "#             sum_value  = value.sum()\n",
    "#             for ix, f in enumerate(value.transpose()):\n",
    "#                 prob_fitur.append((f.sum()+self.alpha)/(sum_value+self.len_fitur))\n",
    "#                 print(c,str(f.sum()), \"+\",str(self.alpha),\"/\", str(sum_value), str(self.len_fitur), self.fitur[ix])\n",
    "#             self.posterior.update({c:prob_fitur})\n",
    "# #         print(self.posterior)\n",
    "\n",
    "#     def predict(self, X_predict):\n",
    "#         self.X_predict = X_predict\n",
    "#         self.inf_dict = dict()\n",
    "#         for c in self.class_: \n",
    "# #             self.sum_predict = dict()\n",
    "#             self.inf_dict.update({c:np.prod(np.power(self.posterior[c],self.X_predict))*self.prior_class[c]})\n",
    "#         return max(self.inf_dict.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha = 1):\n",
    "        self.dic_data_index = dict()\n",
    "        self.dic_data_by_class = dict()\n",
    "        self.dic_data_posterior = dict()\n",
    "        self.dic_data_prob_fitur = dict()\n",
    "        self.prior = dict()\n",
    "        self.class_ = 0\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def train (self, X, y):\n",
    "#         print(X)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        vectorizer = CountVectorizer(binary=True)\n",
    "        self.X = vectorizer.fit_transform(X).A\n",
    "        self.fitur = vectorizer.get_feature_names()\n",
    "        self.len_fitur = len(self.fitur)\n",
    "        self.y = np.array(self.y)\n",
    "        self.class_ = sorted(set(y))\n",
    "        \n",
    "        self.prior_class = dict(zip(Counter(self.y).keys(), Counter(self.y).values()))\n",
    "        for key, value in self.prior_class.items():\n",
    "            self.prior_class.update({key:value/len(self.y)})\n",
    "        \n",
    "        #menghitung jumlah class\n",
    "        self.len_data = len(self.y)\n",
    "\n",
    "        #mencari index data untuk class tertentu\n",
    "        self.dic_data_index = dict()\n",
    "        for i in self.class_:\n",
    "            isi_list = list()\n",
    "            for index, j in enumerate(self.y):\n",
    "        #         print(j)\n",
    "                if i == j:\n",
    "                    isi_list.append(index)\n",
    "            self.dic_data_index.update({i:isi_list})\n",
    "            \n",
    "        self.dic_data_by_class = dict()\n",
    "        for key, value in self.dic_data_index.items():\n",
    "            self.dic_data_by_class.update({key:(self.X[value])})\n",
    "#         dic_data_index\n",
    "        self.dic_data_prob_fitur = dict()\n",
    "        for c, value in self.dic_data_by_class.items():\n",
    "            prob_fitur = list()\n",
    "            sum_value  = value.sum()\n",
    "            for ix, f in enumerate(value.transpose()):\n",
    "                prob_fitur.append((f.sum()+self.alpha)/(len(value)+self.len_fitur))\n",
    "#                 print(c,str(f.sum()), \"+\",str(self.alpha),\"/\", str(len(value)),\"+\", str(self.len_fitur), self.fitur[ix])\n",
    "            bobot_fitur = dict(zip(self.fitur,prob_fitur))\n",
    "            self.dic_data_prob_fitur.update({c:bobot_fitur})\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = sorted(set(X.split()))\n",
    "        try:\n",
    "            self.dict_predict = dict()\n",
    "            for c, value in self.dic_data_prob_fitur.items():\n",
    "    #             print(value)\n",
    "\n",
    "                bobot_fitur = list()\n",
    "                for kata in X:\n",
    "    #                 print(kata)\n",
    "                    if kata in value:\n",
    "                        # print(c,kata,value[kata])\n",
    "                        bobot_fitur.append(value[kata])\n",
    "    #                     print(c, value[kata])\n",
    "                if len(bobot_fitur)>0:\n",
    "                    post_prior = np.prod(bobot_fitur)*self.prior_class[c]\n",
    "    #                 print(bobot_fitur)\n",
    "                    self.dict_predict.update({c:post_prior})\n",
    "            return max(self.dict_predict.items(), key=operator.itemgetter(1))[0]\n",
    "        except:\n",
    "            print(\"err404or\")\n",
    "            return max(self.prior_class.items(), key=operator.itemgetter(1))[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corpus = [\n",
    "    'Chinese Chinese Shanghai',\n",
    "    'Chinese Beijing Chinese',\n",
    "    'Chinese Macao',\n",
    "    'Tokyo Japan Chinese',\n",
    "    'Tokyo Japan',\n",
    "]\n",
    "\n",
    "y = np.array([\"yes\",\"yes\",\"yes\",'no'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "courpus = np.array(corpus)\n",
    "model = NaiveBayesClassifier(alpha = 2)\n",
    "model.train(corpus, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"japan tokyo chinese\")\n",
    "# model.prior_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.10714285714285714, 'yes': 0.16666666666666666}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dict_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': {'beijing': 0.2857142857142857,\n",
       "  'chinese': 0.42857142857142855,\n",
       "  'japan': 0.42857142857142855,\n",
       "  'macao': 0.2857142857142857,\n",
       "  'shanghai': 0.2857142857142857,\n",
       "  'tokyo': 0.42857142857142855},\n",
       " 'yes': {'beijing': 0.3333333333333333,\n",
       "  'chinese': 0.5555555555555556,\n",
       "  'japan': 0.2222222222222222,\n",
       "  'macao': 0.3333333333333333,\n",
       "  'shanghai': 0.3333333333333333,\n",
       "  'tokyo': 0.2222222222222222}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dic_data_prob_fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10714285714285714"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no\n",
    "0.42857142857142855*model.prior_class['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#yes\n",
    "0.2222222222222222*model.prior_class['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 0.75, 'no': 0.25}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prior_class#model.prior_class['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-59-c440149024e9>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-59-c440149024e9>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "*model.prior_class['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
