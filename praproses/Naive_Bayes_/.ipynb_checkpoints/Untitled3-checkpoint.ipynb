{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import naive_bayes as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "(4, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'Chinese Chinese Shanghai',\n",
    "    'Chinese Beijing Chinese',\n",
    "    'Chinese Macao',\n",
    "    'Tokyo Japan Chinese',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "modelT = vectorizer.fit(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print(X.shape)\n",
    "fitur  = vectorizer.get_feature_names()\n",
    "fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2,3,4,5],\n",
    "         [1,2,3,4,5]])\n",
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array([\"yes\",\"yes\",\"yes\",'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nb.MultinominalNaiveBayes()\n",
    "model.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = modelT.transform([\"Chinese Chinese Chinese Tokyo Japan\"])\n",
    "model.predict(new_data[0].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.00013548070246744223, 'yes': 0.00030121377997263036}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.dic_data_by_class['no'].A\n",
    "model.inf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.03823888782011\n",
      "-9.596019352652045\n"
     ]
    }
   ],
   "source": [
    "# model = nb.ComplementNaiveBayes()\n",
    "# model.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(new_data[0].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.dic_data_by_class['yes'].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for yes, no in enumerate(model.dic_data_by_class[\"yes\"].A, model.dic_data_by_class[\"no\"].A):\n",
    "#     print(yes, no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class NBC:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dic_data_index = dict()\n",
    "        self.dic_data_by_class = dict()\n",
    "        self.dic_data_posterior = dict()\n",
    "        self.dic_data_prob_fitur = dict()\n",
    "        self.prior = dict()\n",
    "        self.class_ = 0\n",
    "    def train (self, X, y):\n",
    "#         print(X)\n",
    "        X = [np.array(i.split()) for i in X]\n",
    "\n",
    "        X = np.array(X)\n",
    "#         print(X)\n",
    "        y = np.array(y)\n",
    "        self.class_ = sorted(set(y))\n",
    "\n",
    "        for i in self.class_:\n",
    "            isi_list = list()\n",
    "            for index, j in enumerate(y):\n",
    "        #         print(j)\n",
    "                if i == j:\n",
    "                    isi_list.append(index)\n",
    "            self.dic_data_index.update({i:isi_list})\n",
    "\n",
    "        for key, value in self.dic_data_index.items():\n",
    "#             print(X[value])\n",
    "            self.dic_data_by_class.update({key:X[value]})\n",
    "            self.prior.update({key:len(value)/len(y)})\n",
    "\n",
    "        for key, value in self.dic_data_by_class.items():\n",
    "            words = list()\n",
    "#             print(value)\n",
    "            for i in value:\n",
    "                for kata in set(i): #biner\n",
    "                    words.append(kata)\n",
    "            dict_fitur = dict()\n",
    "#             fitur_bobot = list()\n",
    "#             print(words)\n",
    "            for i in words:\n",
    "                prob_fitur_ = words.count(i)/len(value)\n",
    "#                 print(value)\n",
    "#                 print(i,\"|\",words.count(i),\"/\",len(value),\"===\", key)\n",
    "                dict_fitur.update({i:prob_fitur_})\n",
    "#                 fitur_bobot.append(prob_fitur_)\n",
    "    #         print(np.prod(fitur_bobot))\n",
    "            self.dic_data_prob_fitur.update({key:dict_fitur})\n",
    "#             self.dic_data_posterior.update({key:np.prod(fitur_bobot)})\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.split()\n",
    "        self.dict_predict = dict()\n",
    "        for c, value in self.dic_data_prob_fitur.items():\n",
    "            \n",
    "            bobot_fitur = list()\n",
    "            for kata in X:\n",
    "#                 print(kata)\n",
    "                if kata in value:\n",
    "                    print(c,kata,value[kata])\n",
    "                    bobot_fitur.append(value[kata])\n",
    "#                     print(c, value[kata])\n",
    "            if len(bobot_fitur)>0:\n",
    "                post_prior = np.prod(bobot_fitur)*self.prior[c]\n",
    "#                 print(post_prior)\n",
    "                self.dict_predict.update({c:post_prior})\n",
    "        return max(self.dict_predict.items(), key=operator.itemgetter(1))[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  _counter (corpus, y)\n",
    "model  = NBC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(corpus, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no Chinese 1.0\n",
      "no Tokyo 1.0\n",
      "no Japan 1.0\n",
      "yes Chinese 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Chinese Tokyo Japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0.25, 'yes': 0.75}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dict_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.dic_data_by_class['no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': array([array(['Tokyo', 'Japan', 'Chinese'], dtype='<U7')], dtype=object),\n",
       " 'yes': array([array(['Chinese', 'Chinese', 'Shanghai'], dtype='<U8'),\n",
       "        array(['Chinese', 'Beijing', 'Chinese'], dtype='<U7'),\n",
       "        array(['Chinese', 'Macao'], dtype='<U7')], dtype=object)}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dic_data_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': {'Chinese': 1.0, 'Japan': 1.0, 'Tokyo': 1.0},\n",
       " 'yes': {'Chinese': 1.0,\n",
       "  'Shanghai': 0.3333333333333333,\n",
       "  'Beijing': 0.3333333333333333,\n",
       "  'Macao': 0.3333333333333333}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dic_data_prob_fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "class ComplementNaiveBayes:\n",
    "    def __init__(self,alpha = 1):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len_fitur = len(X.A[0])\n",
    "#         self.fitur = fitur\n",
    "        \n",
    "        self.class_ = sorted(set(self.y))\n",
    "        self.len_fitur = len(self.y)\n",
    "\n",
    "        #mencari index data dengan class tertentu\n",
    "        self.dic_data_index = dict()\n",
    "        for i in self.class_:\n",
    "            isi_list = list()\n",
    "            for index, j in enumerate(self.y):\n",
    "                if i != j: #salah satu dari tahap complement\n",
    "                    isi_list.append(index)\n",
    "            self.dic_data_index.update({i:isi_list})\n",
    "            \n",
    "        self.dic_data_by_class = dict()\n",
    "        for key, value in self.dic_data_index.items():\n",
    "            self.dic_data_by_class.update({key:(self.X[value])})\n",
    "\n",
    "        self.complement = dict()\n",
    "        for c, value in self.dic_data_by_class.items():\n",
    "            prob_wci = list()\n",
    "            sum_value  = value.sum()\n",
    "#           Hitung Complement\n",
    "            for f in value.transpose():\n",
    "#                 f = f.sum() + (self.alpha*len(self.dic_data_index[c])) / sum_value+(self.alpha*len(self.dic_data_index[c]))\n",
    "#                 f = (f.sum()+self.alpha)/(sum_value+self.len_fitur)\n",
    "                f = (f.sum()+self.alpha)/(sum_value+self.len_fitur)\n",
    "#                 print(f, end=\" \")\n",
    "                wci = f#np.log(f)\n",
    "#                 print(wci)\n",
    "                prob_wci.append(wci)\n",
    "#             print(np.sqrt(sum(prob_wci)))\n",
    "            norm_wci = np.array(prob_wci)/sum(prob_wci)\n",
    "            self.complement.update({c:norm_wci})\n",
    "\n",
    "    def predict(self, X_predict):\n",
    "        self.X_predict = X_predict\n",
    "        self.inf_dict = dict()\n",
    "        for c in self.class_:\n",
    "            self.inf_dict.update({c:np.prod(np.power(self.complement[c],self.X_predict))})\n",
    "        return min(self.inf_dict.items(), key=operator.itemgetter(1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ComplementNaiveBayes()\n",
    "model.train(X, y)\n",
    "new_data = modelT.transform([\"Chinese Chinese Chinese Tokyo Japan\"])\n",
    "model.predict(new_data[0].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1]]\n",
      "\n",
      "[[0 2 0 0 1 0]\n",
      " [1 2 0 0 0 0]\n",
      " [0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(model.dic_data_by_class['yes'].A)\n",
    "print(\"\")\n",
    "print(model.dic_data_by_class['no'].A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
